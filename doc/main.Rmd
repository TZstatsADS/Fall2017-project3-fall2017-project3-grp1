---
title: "Project 3 - Example Main Script"
author: "Grp 1"
date: "Oct 21, 2017"
output:
  html_document: default
  pdf_document: default
---

```{r, warning=F}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}

packages.used=c("gbm", "MASS", "OpenImageR", "jpeg", "ggplot2", "reshape2", "randomForest")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE,
                   repos='http://cran.us.r-project.org')
}

## Loading packages
library("EBImage")
library("gbm")
library("MASS")
library("OpenImageR")
library("jpeg")
library("ggplot2")
library("reshape2")
library("randomForest")
```

### Step 0: specify directories.

# Set working directory as where this .rmd file is located.
```{r wkdir, eval=FALSE}
setwd("~/Desktop/Fall2017-project3-fall2017-project3-grp1-master/doc")
```



# Set directories where train and test datasets are located.
```{r, warning=F}
experiment_dir <- "../data/training_set/"
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
#img_test_dir<-"../data/kelly's DOGs/"
```

### Step 1: Set up controls for evaluation experiments.

In this chunk, ,we have a set of controls for the evaluation experiments. 

+ (T/F) cross-validation on the training set
+ (number) K, the number of CV folds
+ (T/F) process features for training set
+ (T/F) run evaluation on an independent test set
+ (T/F) process features for test set

```{r exp_setup, warning=F}
run.cv = F # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train = TRUE # process features for training set
run.test = TRUE # run evaluation on an independent test set
run.feature.test = TRUE # process features for test set
model.train = F
```


### Boolean variables for Feature Extraction procedures

```{r}
run.pca = FALSE
run.hogs = FALSE
run.cnn = TRUE
run.lbp = FALSE
run.sift = FALSE
```

### Boolean variables indicating which model to run

```{r}
run.gbm = FALSE
run.svm = FALSE
run.rf = FALSE
run.lda = FALSE

```

Using cross-validation or independent test set evaluation, we compare the performance of different classifiers or classifiers with different specifications. In the baseline model, we use GBM with different `shrinkage` parameter values. In the following chunk, we list, in a vector, setups (in this case, `depth`) corresponding to models that we will compare. In your project, you maybe comparing very different classifiers. You can assign them numerical IDs and labels specific to your project. 

```{r model_setup, warning=F}
model_values<-seq(0.01,0.25,0.05) #for GBM
#model_labels = paste("GBM with shrinkage value =", model_values) # for GBM

svm_gamma_values <- seq(0, 0.5, by = 0.1)
svm_gamma_labels = paste("SVM gamma =", svm_gamma_values) # for SVM

rf_par = expand.grid(mtry = seq(15,30,3),ntree = seq(500, 2000,500)) #for RF
```

### Step 2: import training images class labels.

```{r train_label, warning=F}
 label_dir <- "../data/training_set/label_train.csv" 
 label_train <- read.csv(label_dir, header=T) 
```

### Step 3: construct visual feature

```{r feature, warning=F}
 source("../lib/feature - final.R")

if( !run.sift ){

tm_feature_train <-  NA
if(run.feature.train){
  tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
                                                       n_pixel_row = 300,
                                                       n_pixel_col = 300,
                                                       n_dig = 4,
                                                       n_hogs = 54,
                                                       desired_variance = 0.9,
                                                       run.pca = run.pca,
                                                       run.hogs = run.hogs,
                                                       run.cnn = run.cnn, 
                                                       run.lbp = run.lbp,
                                                       export=TRUE) )
}

tm_feature_test <- NA
if(run.feature.test){
  tm_feature_test <- system.time(dat_test <- feature(img_test_dir,
                                                       n_pixel_row = 300,
                                                       n_pixel_col = 300,
                                                       n_dig = 4,
                                                       n_hogs = 54,
                                                       desired_variance = 0.9,
                                                       run.pca = run.pca,
                                                       run.hogs = run.hogs,
                                                       run.cnn = run.cnn, 
                                                       run.lbp = run.lbp,
                                                       export=TRUE) )
}

save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")



}

if(run.sift){
  #dat_test <- read.csv(img_test_dir, header=T)
  baseline_dat_train <- read.csv("../data/training_set/sift_train.csv", header=T)
  dat_test <- baseline_dat_train[,-1]
}
```

### Step 4: Train a classification model with training images
Call the train model and test model from library. 

`train.R` and `test.R` should be wrappers for all your model training steps and your classification/prediction steps. 
+ `train.R`
  + Input: a path that points to the training set features.
  + Input: an R object of training sample labels.
  + Output: an RData file that contains trained classifiers in the forms of R objects: models/settings/links to external trained configurations.
+ `test.R`
  + Input: a path that points to the test set features.
  + Input: an R object that contains a trained classifier.
  + Output: an R object of class label predictions on the test set. If there are multiple classifiers under evaluation, there should be multiple sets of label predictions. 
```{r loadlib, warning=F}
source("../lib/train - final.R")
source("../lib/test - final.R")

load("../output/feature_train.RData")
load("../output/feature_test.RData")
```


#### Model selection with cross-validation

```{r runcv, message=FALSE, warning=FALSE}
source("../lib/cross_validation.R")

# if SIFT feature extraction method selected TRUE
if( run.sift ){
  baseline_dat_train <- read.csv("../data/training_set/sift_train.csv", header=T)
  baseline_dat_train <- baseline_dat_train[,-1]
  dat_train <- baseline_dat_train
  #dat_test <- dat_train
}

cv.svm = T
cv.gbm = F
cv.rf = F
cv.lda = F

if(run.cv) {
   
  if( cv.gbm ){
    err_cv <- array(dim=c(length(model_values), 2))
    
    for(k in 1:length(model_values)){
      cat("k=", k, "\n")
      err_cv[k,] <- cv.function( as.data.frame(dat_train), label_train, model_values[k], K, cv.gbm = T)
      #err_cv[k,]<-cv.function(baseline_dat_train,label_train,model_values[k],K,cv.gbm = T)
     }
  }
  
  if( cv.svm ){
    
  err_cv <- array(dim=c(length(svm_gamma_values), 2))
  
   for(k in 1:length(svm_gamma_values)){
    cat("k=", k, "\n")
     err_cv[k,] <- cv.function( dat_train, label_train, d = svm_gamma_values[k], K = K, cv.svm = T)
   }
    
  }
  
 
  
  if( cv.rf ){
    err_cv <- array(dim=c(nrow(rf_par), 2))
    model_values = rf_par
  
    for(k in 1:nrow(rf_par)){
      cat("k=", k, "\n")
      err_cv[k,] <- cv.function( dat_train, label_train, rf_par[k,], K, cv.rf = T)
    }
  }
  
  save(err_cv, file="../output/err_cv.RData")
}

```

Visualize cross-validation results. 

```{r cv_vis, warning=F}
if(run.cv){

  if(cv.gbm){
    load("../output/err_cv.RData")
    #pdf("../fig/cv_results.pdf", width=7, height=5)
    plot(model_values, err_cv[,1], xlab="Shrinkage", ylab="CV Error",
         main="Cross Validation Error", type="n", ylim=c(0, 1))
    points(model_values, err_cv[,1], col="blue", pch=16)
    lines(model_values, err_cv[,1], col="blue")
    arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2], 
    length=0.1, angle=90, code=3)
    #dev.off()
    }
  
  if(cv.svm){
    load("../output/err_cv.RData")
    #pdf("../fig/cv_results.pdf", width=7, height=5)
    plot(svm_gamma_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
         main="Cross Validation Error", type="n", ylim=c(0, 1))
    points(svm_gamma_values, err_cv[,1], col="blue", pch=16)
    lines(svm_gamma_values, err_cv[,1], col="blue")
    arrows(svm_gamma_values, err_cv[,1]-err_cv[,2], svm_gamma_values, err_cv[,1]+err_cv[,2], 
    length=0.1, angle=90, code=3)

  }
  if(cv.rf){
    load('../output/err_cv.RData')
    models <- cbind(rf_par, err_cv)
    colnames(models) <- c('mtry','ntree','err','sd')
    models <- models[,-4]
    #models <- melt(models, id.vars='ntree', value.name="err", variable.name="mtry")
    ggplot(data=models, aes(x=mtry, y=err, group = as.factor(ntree), colour = as.factor(ntree))) +
    geom_line() +
    geom_point( size=4, shape=21, fill="white")
  }

}
```


* Choose the "best"" parameter value
```{r best_model, warning=F}
if(run.cv){

if( !run.rf ){
  model_best=model_values[1]
} else {
  model_best=model_values[1,]
}


if(run.gbm){
  model_best<- model_values[which.min(err_cv[,1])]
}
# if(run.cv){
#   model_best <- svm_gamma_values[which.min(err_cv[,1])]
# }
if(run.svm){
  model_best <- svm_gamma_values[which.min(err_cv[,1])]
}
if(run.rf){
  model_best <- rf_par[which.min(err_cv[,1]),]
}

}
```

* Train the model with the entire training set using the selected model (model parameter) via cross-validation.
```{r final_train, warning=F}

if( !run.cv ){
  
  if( run.gbm){
    model_best <- 0.06
  }
  
  if( run.rf ){
    model_best <- list(mtry = 20, ntree = 2000)
  }
  
  if( run.svm ){
    model_best <- 0.1  
  }
  
}

if( model.train ){
if( run.lda ){
  tm_train_lda <- system.time(model.lda <- train( dat_train, label_train, run.lda = TRUE ))
  save(model.lda, file="../output/model_lda.RData")
}

if( run.gbm ){
  tm_train_gbm <- system.time(model.gbm <- train( as.data.frame(dat_train), label_train, run.gbm = TRUE, params = model_best ))
  save(model.gbm, file="../output/model_gbm.RData")
}

if( run.cnn ){
  tm_train_cnn <- system.time(model.cnn <- train( params = c(img_train_dir, label_dir) ))
  save(model.cnn, file="../output/model_cnn.RData")
}

if( run.svm ){
  tm_train_svm <- system.time(model.svm <- train( dat_train, label_train, run.svm = TRUE, params = model_best ))
  save(model.svm, file="../output/model_svm.RData")
}

if( run.rf ){
  tm_train_rf <- system.time(model.rf <- train(dat_train, label_train, model_best, run.rf = TRUE ))
  save(model.rf, file="../output/model_rf.RData") 
}
  
}
```

### Step 5: Make prediction and Summarize running time
 
```{r final_train&running time, warning=F}
#Import Test labels
label_test <- read.csv("../data/training_set/label_test.csv", header=T)

if( !run.sift ){

cat("Total Time for constructing training features=", tm_feature_train[1], "s \n")

cat("Total Time for constructing testing features=", tm_feature_test[1], "s \n")

}

if( run.lda ){
  load(file = "../output/model_lda.Rdata")
  tm_test_lda <- system.time(pred.lda <- test(model.lda, dat_test, test.lda = T))
  lda.error <- sum((pred.lda != label_test[,2]))/(length(label_test[,2]))
  cat("Test error =", lda.error * 100, "% \n")
  cat("Time for training model=", tm_train_lda[1], "s \n")
  cat("Time for testing model=", tm_test_lda[1], "s \n")
}

if( run.gbm ){
  load(file = "../output/model_gbm.Rdata")
  tm_test_gbm <- system.time(pred.gbm <- test(model.gbm, dat_test, test.gbm = T))
  gbm.error <- sum((pred.gbm != label_test[,2]))/(length(label_test[,2]))
  cat("Test error =", gbm.error * 100, "% \n")
  if(model.train){cat("Time for training model=", tm_train_gbm[1], "s \n")}
  cat("Time for testing model=", tm_test_gbm[1], "s \n")
}

if( run.svm ){
  load(file = "../output/model_svm.Rdata")
  tm_test_svm <- system.time(pred.svm <- test(model.svm, dat_test, test.svm = T))
  svm.error <- sum((pred.svm != label_test[,2]))/(length(label_test[,2]))
  cat("Test error =", svm.error * 100, "% \n")
  cat("Time for training model=", tm_train_svm[1], "s \n")
  cat("Time for testing model=", tm_test_svm[1], "s \n")
}

if( run.cnn ){
  model.cnn <- NULL
  dat_test <- NULL
  tm_test_cnn <- system.time(pred.cnn <- test(model.cnn, dat_test, params = img_test_dir, test.cnn = T))
  cnn.error <- sum((pred.cnn != label_test[,2]))/(length(label_test[,2]))
  cat("Test error =", cnn.error * 100, "% \n")
  cat("Time for training model=", tm_train_cnn[1], "s \n")
  cat("Time for testing model=", tm_test_cnn[1], "s \n")
}

if( run.rf ){
  load(file = "../output/model_rf.Rdata")
  tm_test_rf <- system.time(pred.rf <- test(model.rf, dat_test, test.rf = T))
  rf.error <- sum((pred.rf != label_test[,2]))/(length(label_test[,2]))
  cat("Test error =", rf.error * 100, "% \n")
  cat("Time for training model=", tm_train_rf[1], "s \n")
  cat("Time for testing model=", tm_test_rf[1], "s \n")
}
```


